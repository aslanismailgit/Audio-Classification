Audio Classification using Machine Learning
This app is designed to show integration of tensorflow, flask, by developing a web app to make classification of two different sounds, per say, two persons.
Steps:
1.	Record audio samples from two person
2.	Prepare mfcc for audio records
3.	Traing MultiLayerPersoptron using tensorflow-keras
4.	Save model
5.	Record a sample for prediction
6.	Make the prediction
Since the purpose of this app is to demonstrate integration, model performance may not be too good (can be much better using different structures).

![alt text](https://github.com/aslanismailgit/Audio-Classification/blob/master/images/home.png)

![alt text](https://github.com/aslanismailgit/Audio-Classification/blob/master/images/makeRecord.png)

![alt text](https://github.com/aslanismailgit/Audio-Classification/blob/master/images/prepareData.png)
![alt text](https://github.com/aslanismailgit/Audio-Classification/blob/master/images/trainModel.png)
![alt text](https://github.com/aslanismailgit/Audio-Classification/blob/master/images/loss.png)
![alt text](https://github.com/aslanismailgit/Audio-Classification/blob/master/images/accuracy.png)
![alt text](https://github.com/aslanismailgit/Audio-Classification/blob/master/images/prediction.png)